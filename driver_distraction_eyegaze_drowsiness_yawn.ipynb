{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "678f4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygame\n",
    "!pip install mediapipe\n",
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d2f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import pyttsx3\n",
    "import pygame \n",
    "from pygame import mixer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103fca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = pyttsx3.init() # object creation\n",
    "# text = 'Attention, your are Yawning!'\n",
    "\n",
    "# \"\"\" RATE\"\"\"\n",
    "# engine.setProperty('rate', 120)   \n",
    "# rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "# print (rate)                        #printing current voice rate\n",
    "#   # setting up new voice rate\n",
    "\n",
    "\n",
    "# \"\"\"VOLUME\"\"\"\n",
    "# volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "# print (volume)                          #printing current volume level\n",
    "# engine.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n",
    "\n",
    "# \"\"\"VOICE\"\"\"\n",
    "# voices = engine.getProperty('voices')       #getting details of current voice\n",
    "# engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "# #engine.setProperty('voice', voices[1].id)   #changing index, changes voices. 1 for female\n",
    "\n",
    "# engine.say(text)\n",
    "# engine.runAndWait()\n",
    "# engine.stop()\n",
    "\n",
    "# \"\"\"Saving Voice to a file\"\"\"\n",
    "# # On linux make sure that 'espeak' and 'ffmpeg' are installed\n",
    "# engine.save_to_file(text, 'Yawning.wav')\n",
    "# engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6042b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "# loading in the voices/sounds \n",
    "voice_left = mixer.Sound('left.wav')\n",
    "voice_right = mixer.Sound('Right.wav')\n",
    "voice_down = mixer.Sound('down.wav')\n",
    "eyes_blink= mixer.Sound('eyes_blink.wav')\n",
    "yawn = mixer.Sound('Yawning.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a497cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_right=0\n",
    "counter_down=0\n",
    "counter_left=0\n",
    "FONTS =cv2.FONT_HERSHEY_COMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f048204",
   "metadata": {},
   "outputs": [],
   "source": [
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ] \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6485fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_LIPS =[61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "UPPER_LIPS=[ 185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a7cabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK = (0,0,0)\n",
    "WHITE = (255,255,255)\n",
    "BLUE = (255,0,0)\n",
    "LIGHTBLUE = (180,130,70)\n",
    "RED = (0,0,255)\n",
    "CYAN = (255,255,0)\n",
    "YELLOW =(0,255,255)\n",
    "MAGENTA = (255,0,255)\n",
    "GRAY = (128,128,128)\n",
    "GREEN = (0,255,0)\n",
    "PURPLE = (128,0,128)\n",
    "ORANGE = (0,165,255)\n",
    "PINK = (147,20,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e695ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def landmarksDetection(img, results, draw=False):\n",
    "    img_height, img_width= img.shape[:2]\n",
    "    mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "    if draw :\n",
    "        [cv2.circle(img, p, 2, (0,255,0), -1) for p in mesh_coord]\n",
    "    return mesh_coord\n",
    "\n",
    "def euclaideanDistance(point, point1):\n",
    "    x, y = point\n",
    "    x1, y1 = point1\n",
    "    distance = math.sqrt((x1 - x)**2 + (y1 - y)**2)\n",
    "    return distance\n",
    "\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    # Right eyes \n",
    "    # horizontal line \n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    # vertical line \n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "    # draw lines on right eyes \n",
    "    # cv.line(img, rh_right, rh_left, utils.GREEN, 2)\n",
    "    # cv.line(img, rv_top, rv_bottom, utils.WHITE, 2)\n",
    "\n",
    "    # LEFT_EYE \n",
    "    # horizontal line \n",
    "    lh_right = landmarks[left_indices[0]]\n",
    "    lh_left = landmarks[left_indices[8]]\n",
    "\n",
    "    # vertical line \n",
    "    lv_top = landmarks[left_indices[12]]\n",
    "    lv_bottom = landmarks[left_indices[4]]\n",
    "\n",
    "    rhDistance = euclaideanDistance(rh_right, rh_left)\n",
    "    rvDistance = euclaideanDistance(rv_top, rv_bottom)\n",
    "\n",
    "    lvDistance = euclaideanDistance(lv_top, lv_bottom)\n",
    "    lhDistance = euclaideanDistance(lh_right, lh_left)\n",
    "    \n",
    "    if lvDistance != 0 and lhDistance !=0:\n",
    "        reRatio = rhDistance/rvDistance\n",
    "        leRatio = lhDistance/lvDistance\n",
    "    \n",
    "    ratio = (reRatio+leRatio)/2\n",
    "    return ratio \n",
    "\n",
    "\n",
    "def MouthRatio(img, landmarks, top_indices, bottom_indices):\n",
    "\n",
    "    lip_right = landmarks[bottom_indices[0]]\n",
    "    lip_left = landmarks[bottom_indices[10]]\n",
    "\n",
    "    lip_top = landmarks[top_indices[4]]\n",
    "    lip_bottom = landmarks[bottom_indices[5]]\n",
    "\n",
    "    \n",
    "    lipDistance = euclaideanDistance(lip_top, lip_bottom)\n",
    "\n",
    "    return lipDistance \n",
    "\n",
    "\n",
    "def colorBackgroundText(img, text, font, fontScale, textPos, textThickness=1,textColor=(0,255,0), bgColor=(0,0,0), pad_x=3, pad_y=3):\n",
    "  \n",
    "    (t_w, t_h), _= cv2.getTextSize(text, font, fontScale, textThickness) # getting the text size\n",
    "    x, y = textPos\n",
    "    cv2.rectangle(img, (x-pad_x, y+ pad_y), (x+t_w+pad_x, y-t_h-pad_y), bgColor,-1) # draw rectangle \n",
    "    cv2.putText(img,text, textPos,font, fontScale, textColor,textThickness ) # draw in text\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "Threshold_Frame = [200,350,450]\n",
    "counter = 0\n",
    "counter_eye = 0\n",
    "counter_mouth = 0 \n",
    "Counter_right=0\n",
    "Counter_down=0\n",
    "Counter_left=0\n",
    "counter_left=0\n",
    "counter_right=0\n",
    "counter_down=0\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    # Also convert the color space from BGR to RGB\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Get the result\n",
    "    results = face_mesh.process(image)\n",
    "    \n",
    "    # To improve performance\n",
    "    image.flags.writeable = True\n",
    "    \n",
    "    # Convert the color space from RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "   \n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    if idx == 1:\n",
    "                        nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                        nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 8000)\n",
    "\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                    # Get the 2D Coordinates\n",
    "                    face_2d.append([x, y])\n",
    "\n",
    "                    # Get the 3D Coordinates\n",
    "                    face_3d.append([x, y, lm.z])       \n",
    "            \n",
    "            # Convert it to the NumPy array\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "            # Convert it to the NumPy array\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            # The camera matrix\n",
    "            focal_length = 1 * img_w\n",
    "\n",
    "            cam_matrix = np.array([ [focal_length, 0, img_h / 2],\n",
    "                                    [0, focal_length, img_w / 2],\n",
    "                                    [0, 0, 1]])\n",
    "\n",
    "            # The Distance Matrix\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            # Solve PnP\n",
    "            success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "            # Get rotational matrix\n",
    "            rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "            # Get angles\n",
    "            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "            # Get the y rotation degree\n",
    "            x = angles[0] * 360\n",
    "            y = angles[1] * 360\n",
    "\n",
    "            #Display the nose direction\n",
    "#             nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "#             p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "#             p2 = (int(nose_3d_projection[0][0][0]), int(nose_3d_projection[0][0][1]))\n",
    "            \n",
    "#             cv2.line(image, p1, p2, (255, 0, 0), 2)\n",
    "\n",
    "            # Add the text on the image\n",
    "            if y< -10:\n",
    "                text = \"Looking Left\"\n",
    "                Counter_left += 1             \n",
    "\n",
    "            if y > 10:\n",
    "                text = \"Looking Right\"\n",
    "                Counter_right += 1\n",
    "\n",
    "            if x < -4:\n",
    "                text = \"Looking Down\"\n",
    "                Counter_down += 1\n",
    "              \n",
    "            else:\n",
    "                text = \"Looking Forward\"\n",
    "                \n",
    "#             colorBackgroundText(image,  f' You are : {text}', FONTS, 0.7, (30,30),2, PINK, YELLOW)\n",
    "#             Threshold =  Threshold_Frame ./ \n",
    "            if y< -10:\n",
    "                Counter_right=0\n",
    "                Counter_down=0\n",
    "                Counter_forward=0\n",
    "                counter_down=0\n",
    "                counter_right=0\n",
    "                if Counter_left % Threshold_Frame[counter_left] == 0  and pygame.mixer.get_busy()==0:\n",
    "                    counter_left +=1\n",
    "                    counter_left = counter_left % 3\n",
    "                    if counter_left == 0:\n",
    "                        Counter_left = 0\n",
    "                    #cv2.putText(image, text, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    voice_left.play()\n",
    "            \n",
    "            if  y > 10:\n",
    "                Counter_left=0\n",
    "                Counter_down=0\n",
    "                Counter_forward=0\n",
    "                counter_left=0\n",
    "                counter_down=0\n",
    "                if Counter_right > Threshold_Frame[counter_right] and pygame.mixer.get_busy()==0:\n",
    "                    \n",
    "                    counter_right +=1\n",
    "                    counter_right = counter_right % 3  \n",
    "                    \n",
    "                    if counter_right == 0:\n",
    "                        Counter_right = 0\n",
    "                    \n",
    "                    voice_right.play()\n",
    "                    #cv2.putText(image, text, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "       \n",
    "            if x < -4:\n",
    "                Counter_right=0\n",
    "                Counter_left=0\n",
    "                Counter_forward=0\n",
    "                if Counter_down % Threshold_Frame[counter_down] == 0 and pygame.mixer.get_busy()==0:\n",
    "\n",
    "                    counter_down +=1\n",
    "                    counter_down = counter_down % 3  \n",
    "                    \n",
    "                    if counter_down == 0:\n",
    "                        Counter_down = 0\n",
    "\n",
    "                    #cv2.putText(image, text, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    voice_down.play()\n",
    "              \n",
    "            \n",
    "# -0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0\n",
    "            frame_height, frame_width= image.shape[:2] \n",
    "            \n",
    "            if results.multi_face_landmarks:\n",
    "                mesh_coords = landmarksDetection(image, results, False)\n",
    "                ratio = blinkRatio(image, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "                Mouth_dist= MouthRatio(image, mesh_coords, UPPER_LIPS, LOWER_LIPS)\n",
    "                colorBackgroundText(image,  f'Eyes Clsoed for: {counter_eye} frames', FONTS, 0.7, (30,90),2, LIGHTBLUE, WHITE)\n",
    "                colorBackgroundText(image,  f'Mouth Open for: {counter_mouth} frames', FONTS, 0.7, (30,120),2, LIGHTBLUE, WHITE)\n",
    "                colorBackgroundText(image,  f'Seeing left for: {Counter_left} frames', FONTS, 0.7, (30,150),2, LIGHTBLUE, WHITE)\n",
    "                colorBackgroundText(image,  f'Seeing right for: {Counter_right} frames', FONTS, 0.7, (30,180),2, LIGHTBLUE, WHITE)\n",
    "                colorBackgroundText(image,  f'Seeing Down for : {Counter_down} frames', FONTS, 0.7, (30,210),2, LIGHTBLUE, WHITE)\n",
    "\n",
    "                if ratio > 4.0:\n",
    "                    counter_eye += 1\n",
    "                    if counter_eye > 10 and pygame.mixer.get_busy()==0:\n",
    "                        eyes_blink.play()\n",
    "                        counter_eye = 0\n",
    "                else: \n",
    "                    counter_eye=0\n",
    "#                 print(Mouth_dist)\n",
    "                if 50 < Mouth_dist:\n",
    "                    counter_mouth += 1\n",
    "                    if counter_mouth > 50 and pygame.mixer.get_busy()==0:\n",
    "                        yawn.play()\n",
    "\n",
    "                        counter_mouth = 0\n",
    "                else: \n",
    "                    counter_mouth=0\n",
    "\n",
    "    cv2.imshow('Head Pose Estimation', image)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40a503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
